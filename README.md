# Job Matching API - Deep Learning & NLP

Um sistema completo de matching de vagas utilizando Deep Learning e Processamento de Linguagem Natural (NLP) para conectar candidatos √†s oportunidades mais adequadas ao seu perfil.

## üìã Vis√£o Geral do Projeto

### Objetivo
Este projeto resolve o problema de neg√≥cio de **matching inteligente entre candidatos e vagas de emprego**, utilizando t√©cnicas avan√ßadas de Machine Learning para analisar CVs, descri√ß√µes de vagas e gerar recomenda√ß√µes precisas baseadas em similaridade sem√¢ntica.

### Solu√ß√£o Proposta
Constru√ß√£o de uma pipeline completa de machine learning que inclui:
- Pr√©-processamento de texto e extra√ß√£o de features
- Gera√ß√£o de embeddings sem√¢nticos com Sentence Transformers
- Rede neural personalizada para scoring de compatibilidade
- API REST para predi√ß√µes em tempo real
- Sistema de monitoramento cont√≠nuo com detec√ß√£o de drift


## üõ†Ô∏è Stack Tecnol√≥gica

- **Linguagem**: Python 3.10+
- **Frameworks de ML**: 
  - PyTorch (apenas infer√™ncia, vers√£o 2.0.1, compat√≠vel com CPU)
  - Sentence Transformers (embeddings sem√¢nticos, CPU)
  - scikit-learn (m√©tricas e pr√©-processamento)
- **API**: FastAPI com valida√ß√£o Pydantic
- **Serializa√ß√£o**: joblib e PyTorch (.pth)
- **Testes**: pytest (apenas para desenvolvimento)
- **Empacotamento**: Docker & Docker Compose
- **Deploy**: Cloud VPS ou m√°quina enxuta (sem GPU)

- **Monitoramento**: 
  - Prometheus (m√©tricas)
  - Grafana (dashboards)
  - Loki (agrega√ß√£o de logs)

## ‚ö†Ô∏è Arquivos Grandes

Alguns arquivos de dados e modelos excedem o limite de 100MB do GitHub e n√£o est√£o presentes no reposit√≥rio. Para utilizar o sistema completo, fa√ßa o download dos arquivos grandes diretamente na se√ß√£o de [Releases](https://github.com/caiosaldanha/api-vagas/releases) do GitHub.

- `model/candidate_texts_processed.joblib`
- `data-files/applicants.json`
- Outros arquivos grandes, se necess√°rio

Ap√≥s baixar, coloque-os nas respectivas pastas do projeto.

## üìÅ Estrutura do Projeto

```
api-vagas/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ main.py                    # API FastAPI principal
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_main.py              # Testes unit√°rios principais
‚îÇ   ‚îî‚îÄ‚îÄ test_performance.py       # Testes de performance
‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îú‚îÄ‚îÄ candidate_embeddings.npy          # Embeddings pr√©-computados
‚îÇ   ‚îú‚îÄ‚îÄ job_embeddings.npy               # Embeddings das vagas
‚îÇ   ‚îú‚îÄ‚îÄ job_matching_neural_model.pth    # Modelo neural treinado
‚îÇ   ‚îú‚îÄ‚îÄ candidate_texts_processed.joblib # Textos processados
‚îÇ   ‚îî‚îÄ‚îÄ job_texts_processed.joblib       # Textos de vagas processados
‚îú‚îÄ‚îÄ data-files/
‚îÇ   ‚îú‚îÄ‚îÄ applicants.json          # Dados dos candidatos (195MB)
‚îÇ   ‚îú‚îÄ‚îÄ prospects.json           # Prospects (21MB)
‚îÇ   ‚îî‚îÄ‚îÄ vagas.json              # Vagas dispon√≠veis (37MB)
‚îú‚îÄ‚îÄ monitoring/
‚îÇ   ‚îú‚îÄ‚îÄ prometheus.yml           # Configura√ß√£o Prometheus
‚îÇ   ‚îú‚îÄ‚îÄ loki-config.yml         # Configura√ß√£o Loki
‚îÇ   ‚îú‚îÄ‚îÄ promtail-config.yml     # Configura√ß√£o Promtail
‚îÇ   ‚îî‚îÄ‚îÄ grafana/
‚îÇ       ‚îú‚îÄ‚îÄ datasources/        # Fontes de dados Grafana
‚îÇ       ‚îî‚îÄ‚îÄ dashboards/         # Dashboards pr√©-configurados
‚îú‚îÄ‚îÄ logs/                       # Diret√≥rio de logs
‚îú‚îÄ‚îÄ requirements.txt            # Depend√™ncias Python
‚îú‚îÄ‚îÄ Dockerfile                  # Container da aplica√ß√£o
‚îú‚îÄ‚îÄ docker-compose.yml         # Orquestra√ß√£o completa
‚îú‚îÄ‚îÄ pytest.ini                # Configura√ß√£o de testes
‚îú‚îÄ‚îÄ model_nlp_deep_learning.ipynb  # Notebook de desenvolvimento
‚îî‚îÄ‚îÄ README.md                  # Este arquivo
```

## üöÄ Instru√ß√µes de Deploy


### Pr√©-requisitos
- Docker & Docker Compose
- Python 3.10+ (para desenvolvimento local)
- 4GB+ RAM (suficiente para infer√™ncia)
- **N√£o requer GPU**


### 1. Deploy Completo com Docker Compose (Desenvolvimento Local)

Para desenvolvimento local, use o arquivo de override que mapeia portas:

```bash
# Clone ou acesse o diret√≥rio do projeto
cd api-vagas

# Op√ß√£o 1: Usar o script de deploy (recomendado para local)
./deploy.sh

# Op√ß√£o 2: Comando manual
docker compose -f docker-compose.yml -f docker-compose.local.yml up --build -d

# Verificar status dos containers
docker compose ps

# Visualizar logs em tempo real
docker compose logs -f job-matching-api

# Parar todos os servi√ßos
docker compose -f docker-compose.yml -f docker-compose.local.yml down
```

### 2. Acessar Servi√ßos (Deploy Local)

- **API**: http://localhost:8000
- **Documenta√ß√£o Swagger**: http://localhost:8000/docs
- **Grafana Dashboard**: http://localhost:3000 (admin/admin123)
- **Prometheus**: http://localhost:9090
- **Health Check**: http://localhost:8000/health

### 3. Deploy em VPS com Traefik (Dokploy)

Este projeto est√° configurado para deploy em VPS com Traefik reverse proxy (ex: Dokploy).

**Caracter√≠sticas do deploy em produ√ß√£o:**
- Usa `expose` ao inv√©s de `ports` para evitar conflitos de porta
- Configurado para funcionar com Traefik como reverse proxy
- SSL/TLS autom√°tico via Let's Encrypt
- Subpaths configurados para Prometheus (`/prometheus`) e Grafana (`/grafana`)
- Rede externa `dokploy-network` para comunica√ß√£o com Traefik

**Acessar Servi√ßos (Produ√ß√£o - exemplo com datathon.caiosaldanha.com):**
- **API**: https://datathon.caiosaldanha.com
- **Documenta√ß√£o Swagger**: https://datathon.caiosaldanha.com/docs
- **Grafana Dashboard**: https://datathon.caiosaldanha.com/grafana (admin/admin123)
- **Prometheus**: https://datathon.caiosaldanha.com/prometheus
- **Health Check**: https://datathon.caiosaldanha.com/health

**Configura√ß√£o:**
1. Certifique-se de que o Traefik est√° rodando e a rede `dokploy-network` existe
2. Atualize o dom√≠nio nos labels do `docker-compose.yml` para seu dom√≠nio
3. Deploy com: `docker compose up -d --build`

**Nota:** Loki e Promtail s√£o internos e n√£o t√™m acesso externo (apenas usado pelo Grafana).

### 4. Deploy Local para Desenvolvimento

```bash
# Instalar depend√™ncias
pip install -r requirements.txt

# Executar aplica√ß√£o
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

# Executar testes
pytest tests/ -v --cov=app --cov-report=html

# Ver relat√≥rio de cobertura
open htmlcov/index.html
```

### 5. Comandos √öteis

```bash
# Parar todos os servi√ßos
docker-compose down

# Rebuild apenas a API
docker-compose up --build job-matching-api

# Ver m√©tricas Prometheus
curl http://localhost:8000/metrics

# Logs espec√≠ficos
docker-compose logs grafana
docker-compose logs prometheus
```

## üìä Exemplos de Chamadas √† API

### 1. Health Check

```bash
curl -X GET "http://localhost:8000/health" \
     -H "Content-Type: application/json"
```

**Resposta:**
```json
{
  "status": "healthy",
  "device": "cpu",
  "models_loaded": true,
  "timestamp": "2023-12-01T10:30:00"
}
```

### 2. Predi√ß√£o de Matches - Exemplo B√°sico

```bash
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{
       "candidate": {
         "cv_pt": "Desenvolvedor Python com 3 anos de experi√™ncia em Django e FastAPI. Forma√ß√£o em Ci√™ncia da Computa√ß√£o.",
         "objetivo_profissional": "Trabalhar com desenvolvimento de APIs e sistemas web escal√°veis"
       },
       "jobs": [
         {
           "titulo_vaga": "Desenvolvedor Python Senior",
           "objetivo_vaga": "Desenvolver APIs REST com Python",
           "principais_atividades": "Programa√ß√£o em Python, Django, FastAPI, PostgreSQL",
           "competencia_tecnicas_e_comportamentais": "Python, Django, FastAPI, SQL, Git, trabalho em equipe"
         },
         {
           "titulo_vaga": "Analista de Marketing Digital",
           "objetivo_vaga": "Gerenciar campanhas de marketing digital",
           "principais_atividades": "Google Ads, Facebook Ads, an√°lise de dados",
           "competencia_tecnicas_e_comportamentais": "Marketing digital, Google Analytics, criatividade"
         }
       ],
       "top_k": 5,
       "threshold": 0.3
     }'
```

**Resposta:**
```json
{
  "candidate_processed_text": "desenvolvedor python anos experiencia django fastapi formacao ciencia computacao trabalhar desenvolvimento apis sistemas web escalaveis",
  "recommendations": [
    {
      "job_index": 0,
      "similarity_score": 0.8542,
      "ml_score": 0.9156,
      "job_preview": "desenvolvedor python senior desenvolver apis rest python programacao python django fastapi postgresql python django fastapi sql git trabalho equipe..."
    }
  ],
  "processing_time_ms": 245.8,
  "timestamp": "2023-12-01T10:35:22.123456"
}
```

### 3. Exemplo com Script Python

```python
import requests
import json

# Dados do candidato
candidate_data = {
    "candidate": {
        "cv_pt": "Engenheiro de Machine Learning com experi√™ncia em PyTorch, TensorFlow e MLOps",
        "conhecimentos_tecnicos": "Python, PyTorch, TensorFlow, Docker, Kubernetes, AWS"
    },
    "jobs": [
        {
            "titulo_vaga": "ML Engineer",
            "principais_atividades": "Desenvolver modelos de ML em produ√ß√£o",
            "competencia_tecnicas_e_comportamentais": "Python, PyTorch, MLOps, Docker"
        }
    ],
    "top_k": 3,
    "threshold": 0.5
}

# Fazer requisi√ß√£o
response = requests.post(
    "http://localhost:8000/predict",
    json=candidate_data,
    headers={"Content-Type": "application/json"}
)

# Processar resposta
if response.status_code == 200:
    result = response.json()
    print(f"Encontrados {len(result['recommendations'])} matches")
    for i, match in enumerate(result['recommendations'], 1):
        print(f"{i}. Job {match['job_index']} - Score: {match['ml_score']:.3f}")
else:
    print(f"Erro: {response.status_code} - {response.text}")
```


## üî¨ Pipeline de Machine Learning

### Etapas do Pipeline (API)

1. **Extra√ß√£o de Dados Textuais**
  - Utiliza arquivos serializados da pasta `model` (embeddings e textos processados)
  - N√£o realiza treinamento, apenas predi√ß√£o

2. **Pr√©-processamento de Texto**
  - Convers√£o para min√∫sculas
  - Remo√ß√£o de pontua√ß√£o e n√∫meros
  - Remo√ß√£o de stopwords em portugu√™s
  - Normaliza√ß√£o de espa√ßos

3. **Engenharia de Features**
  - Gera√ß√£o de embeddings sem√¢nticos com Sentence Transformers (all-MiniLM-L6-v2, CPU)
  - Vetores de 384 dimens√µes

4. **Predi√ß√£o**
  - Rede neural carregada via arquivo `.pth` (apenas infer√™ncia)
  - Similaridade coseno + score da rede neural
  - Threshold configur√°vel para filtragem
  - Ranking por score do modelo neural

5. **P√≥s-processamento**
  - Ordena√ß√£o por score decrescente
  - Limita√ß√£o aos top-k resultados
  - Aplica√ß√£o de threshold de confian√ßa

*Nota: M√©tricas do modelo s√£o referentes ao treinamento realizado previamente, n√£o pela API.*

## üìà Monitoramento e Observabilidade

### M√©tricas Dispon√≠veis

- **Requisi√ß√µes por minuto**: Volume de predi√ß√µes
- **Tempo de processamento**: Lat√™ncia da API
- **Score ML m√©dio**: Qualidade das predi√ß√µes
- **Taxa de matches**: Efetividade do modelo
- **Taxa de erro**: Confiabilidade do sistema

### Dashboards Grafana

1. **Overview Geral**: M√©tricas principais em tempo real
2. **Model Drift**: Monitoramento de performance do modelo
3. **API Performance**: Lat√™ncia e throughput
4. **Logs Estruturados**: An√°lise de comportamento

### Alertas Configur√°veis

- Taxa de erro > 5%
- Tempo de processamento > 10s
- Queda na taxa de matches
- Drift significativo no score m√©dio

## üß™ Testes e Qualidade

### Cobertura de Testes: 80%+

```bash
# Executar todos os testes
pytest tests/ -v

# Testes com cobertura
pytest tests/ --cov=app --cov-report=html

# Apenas testes de performance
pytest tests/test_performance.py -v

# Testes com marcadores
pytest -m "not slow" -v
```

### Tipos de Teste

- **Unit√°rios**: Fun√ß√µes individuais e classes
- **Integra√ß√£o**: Pipeline completo de predi√ß√£o
- **Performance**: Carga e escalabilidade
- **API**: Endpoints e valida√ß√£o de dados

## üîß Configura√ß√£o e Customiza√ß√£o

### Vari√°veis de Ambiente

```bash
# Docker Compose
GRAFANA_ADMIN_PASSWORD=admin123
PROMETHEUS_RETENTION=200h

# API
PYTHONPATH=/app
MODEL_DIR=/app/model
LOG_LEVEL=INFO
```

### Ajuste de Hiperpar√¢metros

Editar `app/main.py`:

```python
# Threshold padr√£o para matches
DEFAULT_THRESHOLD = 0.5

# Top-K padr√£o
DEFAULT_TOP_K = 5

# Configura√ß√£o da rede neural
EMBEDDING_DIM = 384
HIDDEN_DIM = 256
```

## üìö Pr√≥ximos Passos

- [ ] Implementar re-treinamento autom√°tico
- [ ] Adicionar suporte a m√∫ltiplos idiomas
- [ ] Integra√ß√£o com sistemas de RH
- [ ] Explicabilidade das recomenda√ß√µes
- [ ] API para feedback e aprendizado cont√≠nuo
- [ ] Deploy em Kubernetes
- [ ] Cache Redis para embeddings
- [ ] Versionamento de modelos com MLflow

## ü§ù Contribui√ß√£o

1. Fork o projeto
2. Crie uma branch: `git checkout -b feature/nova-feature`
3. Commit: `git commit -m 'Adiciona nova feature'`
4. Push: `git push origin feature/nova-feature`
5. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° sob licen√ßa MIT. Consulte o arquivo `LICENSE` para mais detalhes.

## üÜò Suporte

Para d√∫vidas e suporte:
- Abra uma issue no reposit√≥rio
- Consulte a documenta√ß√£o Swagger em `/docs`
- Verifique os logs em tempo real com `docker-compose logs -f`

---

**Desenvolvido com ‚ù§Ô∏è usando Python, PyTorch e FastAPI**